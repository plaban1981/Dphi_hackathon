{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPHI_COVID_Select_keras_pretrained_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Dphi_hackathon/blob/main/DPHI_COVID_Select_keras_pretrained_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Gz8I6SDYFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f839c12-35d7-4a72-fed9-d96096e7b1c0"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1BFc2Lt2N1swO8BKRvLMEyUhLzF52RFvr',\n",
        "dest_path='content/covid_image_data.zip',\n",
        "unzip=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1BFc2Lt2N1swO8BKRvLMEyUhLzF52RFvr into content/covid_image_data.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAD4OSuBD5v4"
      },
      "source": [
        "import pandas as pd # Data analysis and manipultion tool\n",
        "import numpy as np # Fundamental package for linear algebra and multidimensional arrays\n",
        "import tensorflow as tf # Deep Learning Tool\n",
        "import os # OS module in Python provides a way of using operating system dependent functionality\n",
        "import cv2 # Library for image processing\n",
        "from sklearn.model_selection import train_test_split # For splitting the data into train and validation set\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "QQUFifzTEGdN",
        "outputId": "695b5de7-888e-405e-cc04-81c2f6dc0071"
      },
      "source": [
        "labels = pd.read_csv(\"/content/content/covid_image_data/Training_set_covid.csv\")\n",
        "\n",
        "labels.head() \n",
        "file_paths = [[fname, '/content/content/covid_image_data/train/' + fname] for fname in labels['filename']]\n",
        "\n",
        "if len(labels) == len(file_paths):\n",
        "  print('Number of labels i.e. ', len(labels), 'matches the number of filenames i.e. ', len(file_paths))\n",
        "else:\n",
        "  print('Number of labels does not match the number of filenames')\n",
        "\n",
        "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
        "images.head()\n",
        "\n",
        "\n",
        "train_data = pd.merge(images, labels, how = 'inner', on = 'filename')\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of labels i.e.  3479 matches the number of filenames i.e.  3479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepaths</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "      <td>/content/content/covid_image_data/train/Image_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "      <td>/content/content/covid_image_data/train/Image_...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "      <td>/content/content/covid_image_data/train/Image_...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "      <td>/content/content/covid_image_data/train/Image_...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "      <td>/content/content/covid_image_data/train/Image_...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename                                          filepaths  label\n",
              "0  Image_1.jpg  /content/content/covid_image_data/train/Image_...      1\n",
              "1  Image_2.jpg  /content/content/covid_image_data/train/Image_...      0\n",
              "2  Image_3.jpg  /content/content/covid_image_data/train/Image_...      0\n",
              "3  Image_4.jpg  /content/content/covid_image_data/train/Image_...      0\n",
              "4  Image_5.jpg  /content/content/covid_image_data/train/Image_...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob_afNPui8JL",
        "outputId": "6dd949fe-3dc2-46a2-a805-a7b486b8a14d"
      },
      "source": [
        "train_data[train_data['label'] == 0].shape,train_data[train_data['label'] == 1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3073, 3), (406, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKWZ4L2jjbEa"
      },
      "source": [
        "train_data0 = train_data[train_data['label'] == 0].sample(n=406,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlz2habil0qD",
        "outputId": "42a4bd3e-ffca-4afd-d8f2-8f45dd6ce677"
      },
      "source": [
        "train_data0.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(406, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3i3yNgtl4oy"
      },
      "source": [
        "train_data1 = train_data[train_data['label'] == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaIgBe6rl-ai"
      },
      "source": [
        "train_data = pd.concat([train_data0,train_data1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXPdr5s5mWAJ",
        "outputId": "53043b9a-54fb-4b50-db18-39cdeda0257a"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(812, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx-KcqoBmjpZ"
      },
      "source": [
        "train_data = train_data.reset_index()\n",
        "train_data = train_data.drop('index',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "tD8YgkMMm9Za",
        "outputId": "6075a135-1f59-4873-ba48-7e99f21dfc54"
      },
      "source": [
        "train_data = train_data[['filename','filepaths','label']]\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepaths</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_3045.jpg</td>\n",
              "      <td>/content/content/covid_image_data/train/Image_...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2003.jpg</td>\n",
              "      <td>/content/content/covid_image_data/train/Image_...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_2862.jpg</td>\n",
              "      <td>/content/content/covid_image_data/train/Image_...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_229.jpg</td>\n",
              "      <td>/content/content/covid_image_data/train/Image_...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_276.jpg</td>\n",
              "      <td>/content/content/covid_image_data/train/Image_...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         filename                                          filepaths  label\n",
              "0  Image_3045.jpg  /content/content/covid_image_data/train/Image_...      0\n",
              "1  Image_2003.jpg  /content/content/covid_image_data/train/Image_...      0\n",
              "2  Image_2862.jpg  /content/content/covid_image_data/train/Image_...      0\n",
              "3   Image_229.jpg  /content/content/covid_image_data/train/Image_...      0\n",
              "4   Image_276.jpg  /content/content/covid_image_data/train/Image_...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "c3C0-4fge2wc",
        "outputId": "1a823958-51be-4740-8eae-b50e8c981cd9"
      },
      "source": [
        "test_image_order = pd.read_csv(\"/content/content/covid_image_data/Testing_set_covid.csv\")\n",
        "test_image_order.head()\n",
        "\n",
        "file_paths_test = [[fname, '/content/content/covid_image_data/test/' + fname] for fname in test_image_order['filename']]\n",
        "\n",
        "test_images = pd.DataFrame(file_paths_test, columns=['filename', 'filepaths'])\n",
        "test_images.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepaths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "      <td>/content/content/covid_image_data/test/Image_1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "      <td>/content/content/covid_image_data/test/Image_2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "      <td>/content/content/covid_image_data/test/Image_3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "      <td>/content/content/covid_image_data/test/Image_4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "      <td>/content/content/covid_image_data/test/Image_5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename                                          filepaths\n",
              "0  Image_1.jpg  /content/content/covid_image_data/test/Image_1...\n",
              "1  Image_2.jpg  /content/content/covid_image_data/test/Image_2...\n",
              "2  Image_3.jpg  /content/content/covid_image_data/test/Image_3...\n",
              "3  Image_4.jpg  /content/content/covid_image_data/test/Image_4...\n",
              "4  Image_5.jpg  /content/content/covid_image_data/test/Image_5..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6RE61AjE8kd"
      },
      "source": [
        "data = [] \n",
        "image_size = 331\n",
        "test_pixel_data = []\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "\n",
        "  img_array = cv2.imread(train_data['filepaths'][i], cv2.COLOR_BGR2RGB) \n",
        "\n",
        "  new_img_array = cv2.resize(img_array, (image_size, image_size))\n",
        "  #new_img_array = cv2.GaussianBlur(new_img_array,(5,5),0)\n",
        "  data.append([new_img_array, train_data['label'][i]])\n",
        "\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "\n",
        "  img_array = cv2.imread(test_images['filepaths'][i], cv2.COLOR_BGR2RGB) \n",
        "\n",
        "  new_img_array = cv2.resize(img_array, (image_size, image_size))\n",
        "  #new_img_array = cv2.GaussianBlur(new_img_array,(5,5),0)\n",
        "  test_pixel_data.append(new_img_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0UDTWhMkkca",
        "outputId": "8e08b8f8-9352-49f6-ed77-f61f461204e3"
      },
      "source": [
        "print(len(data),len(test_pixel_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "812 870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jUawuG6FCBJ"
      },
      "source": [
        "np.random.shuffle(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gifw7RXUFQD9"
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "counter = 406\n",
        "\n",
        "for image in data:\n",
        "  # if image[1] == 0 and counter >= 0:\n",
        "  #   x.append(image[0])\n",
        "  #   y.append(image[1])\n",
        "  #   counter -= 1\n",
        "\n",
        "  # elif image[1] == 1:\n",
        "  #   x.append(image[0])\n",
        "  #   y.append(image[1])\n",
        "\n",
        "\n",
        "  x.append(image[0])\n",
        "  y.append(image[1])\n",
        "\n",
        "# converting x & y to numpy array as they are list\n",
        "x = np.array(x)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFYtSBwuFZqJ",
        "outputId": "b8ccf48f-106e-4f99-85cb-0c0b7321a50d"
      },
      "source": [
        "np.unique(y, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([3073,  406]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvqVdNybI_5l",
        "outputId": "8a67bae1-2e20-4144-bbc7-0eb4a70191ec"
      },
      "source": [
        " pd.Series(y).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3073\n",
              "1     406\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH3ZdHeMJoC2"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(x,y,test_size=0.1, random_state = 42,stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfOC9tO4kyOa",
        "outputId": "0409b2ea-bce5-4638-f35b-3bdbfa564200"
      },
      "source": [
        "test_pixel_data = np.array(test_pixel_data)\n",
        "\n",
        "test_pixel_data = test_pixel_data/255\n",
        "\n",
        "print(X_train.shape,X_val.shape,test_pixel_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(730, 331, 331, 3) (82, 331, 331, 3) (870, 331, 331, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6is3MYP3saQr"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = train_datagen.flow(X_train,y_train,batch_size=32)\n",
        "\n",
        "val_generator = val_datagen.flow(X_val,y_val,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9mkXtRJMCEw",
        "outputId": "3f887046-acc0-4068-a1a6-9330454f16be"
      },
      "source": [
        "pd.Series(y_val).value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.883621\n",
              "1    0.116379\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7JYPkjvMGad",
        "outputId": "f167ea57-8289-49eb-9974-05a0a3f4493f"
      },
      "source": [
        "pd.Series(y_train).value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.88322\n",
              "1    0.11678\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3SwxsPo30jI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4f78b3-f019-424c-e7e4-4b2804709110"
      },
      "source": [
        "print(X_train.shape,X_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(730, 331, 331, 3) (82, 331, 331, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgsoDecALB6a"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z83JuRvsHxao"
      },
      "source": [
        "cbs = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-5, verbose=0),\n",
        "           tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=4, verbose=1, mode='auto')]\n",
        "\n",
        "# lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "#     monitor=\"val_loss\",\n",
        "#     factor=0.1,\n",
        "#     patience=2,\n",
        "#     verbose=0,\n",
        "#     mode=\"auto\",\n",
        "#     min_delta=0.0001,\n",
        "#     cooldown=0,\n",
        "#     min_lr=0.00001,\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miDHZksN8K9n"
      },
      "source": [
        "from keras.applications import VGG16,VGG19,NASNetLarge,DenseNet201\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "from keras.regularizers import *\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LkvnfzWQknG"
      },
      "source": [
        "**This is the densenet architecture that scores a F1 Score of 91.4572864321608 on submission. Here I have reduced the number of dense layer or fully connected layer and it improved the scores from 88.55721393034825 in case of 3 fully connected layer to 91.4572864321608**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfl2WscyuGnu"
      },
      "source": [
        "initializer = tf.keras.initializers.he_normal(seed=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WNM7sehKBlj"
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    conv_base = NASNetLarge(input_shape=(331,331,3), include_top=False, pooling='max',weights='imagenet')\n",
        "    model.add(conv_base)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    #for layer in model.layers:\n",
        "    #  layer.trainable = True\n",
        "    train_layers = [layer for layer in conv_base.layers[::-1][:5]]\n",
        "    \n",
        "    for layer in conv_base.layers:\n",
        "      if layer in train_layers:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy',get_f1])\n",
        "    \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqVDlAZRuqEz",
        "outputId": "9c65259f-f84f-4521-cc9c-7c23ee10826e"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "NASNet (Functional)          (None, 4032)              84916818  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4032)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               2064896   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 87,156,307\n",
            "Trainable params: 86,959,639\n",
            "Non-trainable params: 196,668\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKxc15OAHL-h"
      },
      "source": [
        "#### **New run without change in parameters to try out different threshold values of prediction probability  run-2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "SBR-8aZ5HEG6",
        "outputId": "0931385e-cf95-4560-9c48-4b73159900e2"
      },
      "source": [
        "model.fit(train_generator,\n",
        "          steps_per_epoch=10,\n",
        "          epochs=25,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=10,\n",
        "          callbacks=[cbs],\n",
        "          class_weight={0:1,1:2})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-e5e7be1313c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           class_weight={0:1,1:2})\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,336,21,21] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential/NASNet/separable_conv_1_reduction_right2_reduce_6/separable_conv2d (defined at <ipython-input-34-9703fabfcde1>:7) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_89213]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp7SMJW9LrWu",
        "outputId": "cc2c906f-0b72-4491-84b7-d7744964bcb4"
      },
      "source": [
        "preds = model.predict(test_pixel_data)\n",
        "#\n",
        "predictions = []\n",
        "for i in preds:\n",
        "  if i[0] >= 0.52:\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)\n",
        "#\n",
        "result = pd.DataFrame(predictions,columns=['prediction'])\n",
        "#\n",
        "print(result.value_counts())\n",
        "#\n",
        "result.to_csv('denseNet201.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction\n",
            "0             762\n",
            "1             108\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mHbYc6YVcoR"
      },
      "source": [
        "threshold 32 : 90.90909090909089\n",
        "\n",
        "threshold 31 : 90.49773755656109\n",
        "\n",
        "threshold 38: 91.32420091324201\n",
        "\n",
        "threshold 50 : 89.81481481481481"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcRvb1MmIWeL"
      },
      "source": [
        "import random\n",
        "threshold_list = []\n",
        "for i in range(10):\n",
        "  threshold_list.append(random.uniform(0.49, 0.50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja-n_OGsPo4v",
        "outputId": "35ce6379-370f-4d6c-9832-43eca45d4781"
      },
      "source": [
        "threshold_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4904089180098008,\n",
              " 0.49295673199614287,\n",
              " 0.49445799594490364,\n",
              " 0.49300604128345055,\n",
              " 0.49720410762675477,\n",
              " 0.49774674375093764,\n",
              " 0.49288225069387265,\n",
              " 0.4961237429887291,\n",
              " 0.49381072519431807,\n",
              " 0.49848581878449216]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "lXKbdQpYIUGs",
        "outputId": "79967423-b33a-4c96-9ace-83f9dfd2410c"
      },
      "source": [
        "preds =  model.predict(X_val/255.0)\n",
        "predictions = []\n",
        "f1score = []\n",
        "threshold_dict = {}\n",
        "for j in threshold_list:\n",
        "  for i in preds:\n",
        "    if i > j:\n",
        "      predictions.append(1)\n",
        "    else:\n",
        "      predictions.append(0)\n",
        "  fscore = f1_score(y_val,predictions)\n",
        "  print(fscore)\n",
        "  #threshold_dict[j] = f1_score(y_val,predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c62a962bbdfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf1score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mthreshold_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreshold_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsDeKSwYPaR3",
        "outputId": "c4975b4d-706a-4b10-9a12-6211cf430daf"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_val,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8142857142857142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF91W2zrHGWd"
      },
      "source": [
        "#### **Previous Run -1 which gave a score of 91.45%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAmZXzmbTkkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c4c07b-3ad1-4a3d-f0a9-beabb87a1e31"
      },
      "source": [
        "model.fit(train_generator,steps_per_epoch=87,epochs=100,validation_data=val_generator,validation_steps=22,callbacks=[cbs],class_weight={0:1,1:2})\n",
        "\n",
        "#model.fit(train_generator,steps_per_epoch=21,epochs=50,validation_data=val_generator,validation_steps=6,callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "87/87 [==============================] - 51s 591ms/step - loss: 628.4645 - accuracy: 0.7492 - get_f1: 0.4643 - val_loss: 481.3228 - val_accuracy: 0.2141 - val_get_f1: 0.2211\n",
            "Epoch 2/100\n",
            "87/87 [==============================] - 50s 577ms/step - loss: 361.3675 - accuracy: 0.8983 - get_f1: 0.6859 - val_loss: 253.7653 - val_accuracy: 0.1480 - val_get_f1: 0.2078\n",
            "Epoch 3/100\n",
            "87/87 [==============================] - 50s 572ms/step - loss: 170.8621 - accuracy: 0.9457 - get_f1: 0.7992 - val_loss: 100.9907 - val_accuracy: 0.5014 - val_get_f1: 0.3036\n",
            "Epoch 4/100\n",
            "87/87 [==============================] - 50s 572ms/step - loss: 55.3404 - accuracy: 0.9501 - get_f1: 0.8058 - val_loss: 21.8934 - val_accuracy: 0.8017 - val_get_f1: 0.5024\n",
            "Epoch 5/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 10.4025 - accuracy: 0.9188 - get_f1: 0.7223 - val_loss: 4.7571 - val_accuracy: 0.9267 - val_get_f1: 0.5810\n",
            "Epoch 6/100\n",
            "87/87 [==============================] - 50s 573ms/step - loss: 3.0527 - accuracy: 0.9544 - get_f1: 0.8120 - val_loss: 4.5317 - val_accuracy: 0.2859 - val_get_f1: 0.2367\n",
            "Epoch 7/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 1.7750 - accuracy: 0.9558 - get_f1: 0.8137 - val_loss: 1.1097 - val_accuracy: 0.9555 - val_get_f1: 0.7543\n",
            "Epoch 8/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.7945 - accuracy: 0.9842 - get_f1: 0.9109 - val_loss: 0.8522 - val_accuracy: 0.9598 - val_get_f1: 0.8195\n",
            "Epoch 9/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.6343 - accuracy: 0.9935 - get_f1: 0.9498 - val_loss: 0.7770 - val_accuracy: 0.9626 - val_get_f1: 0.8401\n",
            "Epoch 10/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.6154 - accuracy: 0.9932 - get_f1: 0.9253 - val_loss: 0.6746 - val_accuracy: 0.9540 - val_get_f1: 0.7469\n",
            "Epoch 11/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.6069 - accuracy: 0.9935 - get_f1: 0.9392 - val_loss: 0.6377 - val_accuracy: 0.9583 - val_get_f1: 0.7242\n",
            "Epoch 12/100\n",
            "87/87 [==============================] - 50s 573ms/step - loss: 0.5995 - accuracy: 0.9953 - get_f1: 0.9667 - val_loss: 0.6140 - val_accuracy: 0.9569 - val_get_f1: 0.7322\n",
            "Epoch 13/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.5411 - accuracy: 0.9986 - get_f1: 0.9832 - val_loss: 0.6156 - val_accuracy: 0.9583 - val_get_f1: 0.7661\n",
            "Epoch 14/100\n",
            "87/87 [==============================] - 50s 573ms/step - loss: 0.3233 - accuracy: 0.9989 - get_f1: 0.9836 - val_loss: 0.5628 - val_accuracy: 0.9670 - val_get_f1: 0.8709\n",
            "Epoch 15/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.3439 - accuracy: 0.9964 - get_f1: 0.9678 - val_loss: 0.3987 - val_accuracy: 0.9698 - val_get_f1: 0.8603\n",
            "Epoch 16/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.2852 - accuracy: 0.9996 - get_f1: 0.9991 - val_loss: 0.3513 - val_accuracy: 0.9698 - val_get_f1: 0.7943\n",
            "Epoch 17/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.3169 - accuracy: 0.9960 - get_f1: 0.9652 - val_loss: 0.5025 - val_accuracy: 0.9583 - val_get_f1: 0.7940\n",
            "Epoch 18/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.2625 - accuracy: 0.9968 - get_f1: 0.9594 - val_loss: 0.3355 - val_accuracy: 0.9713 - val_get_f1: 0.8251\n",
            "Epoch 19/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.1835 - accuracy: 0.9975 - get_f1: 0.9530 - val_loss: 0.2630 - val_accuracy: 0.9626 - val_get_f1: 0.7947\n",
            "Epoch 20/100\n",
            "87/87 [==============================] - 50s 576ms/step - loss: 0.1759 - accuracy: 0.9989 - get_f1: 0.9885 - val_loss: 0.2714 - val_accuracy: 0.9598 - val_get_f1: 0.7637\n",
            "Epoch 21/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.1178 - accuracy: 0.9993 - get_f1: 0.9885 - val_loss: 0.1994 - val_accuracy: 0.9670 - val_get_f1: 0.8477\n",
            "Epoch 22/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.1119 - accuracy: 0.9993 - get_f1: 0.9770 - val_loss: 0.2108 - val_accuracy: 0.9684 - val_get_f1: 0.8031\n",
            "Epoch 23/100\n",
            "87/87 [==============================] - 50s 577ms/step - loss: 0.0962 - accuracy: 1.0000 - get_f1: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9684 - val_get_f1: 0.7393\n",
            "Epoch 24/100\n",
            "87/87 [==============================] - 50s 576ms/step - loss: 0.0932 - accuracy: 0.9996 - get_f1: 0.9992 - val_loss: 0.1796 - val_accuracy: 0.9670 - val_get_f1: 0.8594\n",
            "Epoch 25/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.0973 - accuracy: 0.9996 - get_f1: 0.9885 - val_loss: 0.2112 - val_accuracy: 0.9741 - val_get_f1: 0.8804\n",
            "Epoch 26/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.1032 - accuracy: 0.9986 - get_f1: 0.9425 - val_loss: 0.1800 - val_accuracy: 0.9670 - val_get_f1: 0.8311\n",
            "Epoch 27/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.1067 - accuracy: 0.9989 - get_f1: 0.9752 - val_loss: 0.1882 - val_accuracy: 0.9698 - val_get_f1: 0.8360\n",
            "Epoch 28/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.0894 - accuracy: 1.0000 - get_f1: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9727 - val_get_f1: 0.7675\n",
            "Epoch 29/100\n",
            "87/87 [==============================] - 50s 572ms/step - loss: 0.0974 - accuracy: 0.9986 - get_f1: 0.9876 - val_loss: 0.2234 - val_accuracy: 0.9698 - val_get_f1: 0.7913\n",
            "Epoch 30/100\n",
            "87/87 [==============================] - 50s 571ms/step - loss: 0.0978 - accuracy: 0.9996 - get_f1: 0.9885 - val_loss: 0.1794 - val_accuracy: 0.9684 - val_get_f1: 0.8239\n",
            "Epoch 31/100\n",
            "87/87 [==============================] - 50s 571ms/step - loss: 0.0894 - accuracy: 0.9993 - get_f1: 0.9885 - val_loss: 0.1753 - val_accuracy: 0.9670 - val_get_f1: 0.7750\n",
            "Epoch 32/100\n",
            "87/87 [==============================] - 50s 573ms/step - loss: 0.0937 - accuracy: 0.9989 - get_f1: 0.9770 - val_loss: 0.1751 - val_accuracy: 0.9698 - val_get_f1: 0.8746\n",
            "Epoch 33/100\n",
            "87/87 [==============================] - 50s 573ms/step - loss: 0.0894 - accuracy: 1.0000 - get_f1: 0.9770 - val_loss: 0.1719 - val_accuracy: 0.9670 - val_get_f1: 0.8036\n",
            "Epoch 34/100\n",
            "87/87 [==============================] - 50s 572ms/step - loss: 0.0908 - accuracy: 0.9996 - get_f1: 0.9655 - val_loss: 0.1980 - val_accuracy: 0.9727 - val_get_f1: 0.8842\n",
            "Epoch 35/100\n",
            "87/87 [==============================] - 50s 572ms/step - loss: 0.1004 - accuracy: 0.9982 - get_f1: 0.9880 - val_loss: 0.2026 - val_accuracy: 0.9713 - val_get_f1: 0.8764\n",
            "Epoch 36/100\n",
            "87/87 [==============================] - 50s 573ms/step - loss: 0.0926 - accuracy: 0.9986 - get_f1: 0.9770 - val_loss: 0.2261 - val_accuracy: 0.9741 - val_get_f1: 0.8084\n",
            "Epoch 37/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.0875 - accuracy: 1.0000 - get_f1: 0.9885 - val_loss: 0.1673 - val_accuracy: 0.9670 - val_get_f1: 0.7804\n",
            "Epoch 38/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.0912 - accuracy: 0.9996 - get_f1: 0.9770 - val_loss: 0.1792 - val_accuracy: 0.9684 - val_get_f1: 0.8332\n",
            "Epoch 39/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.0854 - accuracy: 1.0000 - get_f1: 0.9885 - val_loss: 0.1814 - val_accuracy: 0.9684 - val_get_f1: 0.8595\n",
            "Epoch 40/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.0899 - accuracy: 1.0000 - get_f1: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9741 - val_get_f1: 0.8775\n",
            "Epoch 41/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.1156 - accuracy: 0.9993 - get_f1: 0.9885 - val_loss: 0.1785 - val_accuracy: 0.9684 - val_get_f1: 0.7564\n",
            "Epoch 42/100\n",
            "87/87 [==============================] - 50s 572ms/step - loss: 0.0886 - accuracy: 0.9986 - get_f1: 0.9747 - val_loss: 0.2784 - val_accuracy: 0.9684 - val_get_f1: 0.8622\n",
            "Epoch 43/100\n",
            "87/87 [==============================] - 50s 572ms/step - loss: 0.1172 - accuracy: 0.9968 - get_f1: 0.9860 - val_loss: 0.1958 - val_accuracy: 0.9698 - val_get_f1: 0.8518\n",
            "Epoch 44/100\n",
            "87/87 [==============================] - 50s 573ms/step - loss: 0.0905 - accuracy: 0.9982 - get_f1: 0.9770 - val_loss: 0.1960 - val_accuracy: 0.9698 - val_get_f1: 0.7782\n",
            "Epoch 45/100\n",
            "87/87 [==============================] - 50s 575ms/step - loss: 0.0940 - accuracy: 0.9993 - get_f1: 0.9885 - val_loss: 0.2004 - val_accuracy: 0.9670 - val_get_f1: 0.7871\n",
            "Epoch 46/100\n",
            "87/87 [==============================] - 50s 573ms/step - loss: 0.0857 - accuracy: 0.9993 - get_f1: 0.9540 - val_loss: 0.1817 - val_accuracy: 0.9641 - val_get_f1: 0.8413\n",
            "Epoch 47/100\n",
            "87/87 [==============================] - 50s 574ms/step - loss: 0.0989 - accuracy: 0.9986 - get_f1: 0.9650 - val_loss: 0.1693 - val_accuracy: 0.9655 - val_get_f1: 0.6753\n",
            "Epoch 00047: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbd09acb978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku9-Hmw9aIbc"
      },
      "source": [
        "preds =  model.predict(X_val/255.0)\n",
        "predictions = []\n",
        "for i in preds:\n",
        "  if i[0] > 0.5:\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK_sTZggaZz7",
        "outputId": "007c607e-bd1d-4f7d-c8eb-55f38b49bcd6"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_val,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8461538461538461"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tlBuKA4BrDz"
      },
      "source": [
        "**Final Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOkonX0BkFAu"
      },
      "source": [
        "preds = model.predict(test_pixel_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUxHa53XmGGe"
      },
      "source": [
        "predictions = []\n",
        "for i in preds:\n",
        "  if i[0] > 0.5:\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIPGCdlHmIfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c6a34f-9b9e-4c06-a513-7ccf6362bbe2"
      },
      "source": [
        "result = pd.DataFrame(predictions,columns=['prediction'])\n",
        "\n",
        "result.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "prediction\n",
              "0             773\n",
              "1              97\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Gp9C1NmRdJ"
      },
      "source": [
        "result.to_csv('denseNet201_last_five2.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzxr2r2gQdEb"
      },
      "source": [
        "#### **Dphi Scores:91.4572864321608**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXBbxyGjVItb"
      },
      "source": [
        "#### **ResNet101 - Experiment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0rYy3MHXwOg"
      },
      "source": [
        "*****************************************************************************************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXeNMuNr7my3"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTl2RElw7hvd"
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    conv_base = ResNet50(input_shape=(224,224,3), include_top=False, pooling='max',weights='imagenet')\n",
        "    model.add(conv_base)\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    # model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n",
        "    # model.add(BatchNormalization())\n",
        "    # model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n",
        "    # model.add(BatchNormalization())\n",
        "    # model.add(Dense(1024, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
        "    # model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    for layer in model.layers:\n",
        "      layer.trainable = True\n",
        "    #train_layers = [layer for layer in conv_base.layers[::-1][:5]]\n",
        "    \"\"\"\n",
        "    for layer in conv_base.layers:\n",
        "      if layer in train_layers:\n",
        "        layer.trainable = True\n",
        "    \"\"\"\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy',get_f1])\n",
        "    \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR_K8imJ73-n",
        "outputId": "d6f49375-df0d-4e65-aebd-62151a4bc31c"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 27,802,497\n",
            "Trainable params: 27,741,185\n",
            "Non-trainable params: 61,312\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PyuUEVN79kn",
        "outputId": "6cd82ab5-aef6-4887-bec8-4387aae6f5b4"
      },
      "source": [
        "history = model.fit(train_generator,steps_per_epoch=87,epochs=100,validation_data=val_generator,validation_steps=22,callbacks=[cbs],class_weight={0:1,1:2})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 2/87 [..............................] - ETA: 13s - loss: 822.2814 - accuracy: 0.5312 - get_f1: 0.1181WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1314s vs `on_train_batch_end` time: 0.1971s). Check your callbacks.\n",
            "87/87 [==============================] - 32s 372ms/step - loss: 657.4409 - accuracy: 0.7600 - get_f1: 0.4747 - val_loss: 500.6789 - val_accuracy: 0.8836 - val_get_f1: 0.0000e+00\n",
            "Epoch 2/100\n",
            "87/87 [==============================] - 31s 353ms/step - loss: 374.4339 - accuracy: 0.9102 - get_f1: 0.7074 - val_loss: 259.8387 - val_accuracy: 0.8362 - val_get_f1: 0.0485\n",
            "Epoch 3/100\n",
            "87/87 [==============================] - 31s 356ms/step - loss: 174.0380 - accuracy: 0.9475 - get_f1: 0.7841 - val_loss: 102.0960 - val_accuracy: 0.1164 - val_get_f1: 0.2057\n",
            "Epoch 4/100\n",
            "87/87 [==============================] - 31s 361ms/step - loss: 55.5814 - accuracy: 0.9242 - get_f1: 0.7338 - val_loss: 22.8347 - val_accuracy: 0.8836 - val_get_f1: 0.0000e+00\n",
            "Epoch 5/100\n",
            "87/87 [==============================] - 32s 364ms/step - loss: 10.6935 - accuracy: 0.9346 - get_f1: 0.7530 - val_loss: 4.9400 - val_accuracy: 0.8836 - val_get_f1: 0.0000e+00\n",
            "Epoch 6/100\n",
            "87/87 [==============================] - 32s 367ms/step - loss: 5.2109 - accuracy: 0.9062 - get_f1: 0.6865 - val_loss: 5.5466 - val_accuracy: 0.8434 - val_get_f1: 0.0945\n",
            "Epoch 7/100\n",
            "87/87 [==============================] - 32s 369ms/step - loss: 2.8935 - accuracy: 0.9461 - get_f1: 0.7838 - val_loss: 3.6156 - val_accuracy: 0.2945 - val_get_f1: 0.1359\n",
            "Epoch 8/100\n",
            "87/87 [==============================] - 32s 373ms/step - loss: 0.7757 - accuracy: 0.9860 - get_f1: 0.9307 - val_loss: 2.2866 - val_accuracy: 0.1164 - val_get_f1: 0.2049\n",
            "Epoch 9/100\n",
            "87/87 [==============================] - 33s 377ms/step - loss: 0.4389 - accuracy: 0.9935 - get_f1: 0.9628 - val_loss: 2.1921 - val_accuracy: 0.1250 - val_get_f1: 0.1954\n",
            "Epoch 10/100\n",
            "87/87 [==============================] - 33s 377ms/step - loss: 0.5801 - accuracy: 0.9889 - get_f1: 0.9351 - val_loss: 3.2755 - val_accuracy: 0.3520 - val_get_f1: 0.2067\n",
            "Epoch 11/100\n",
            "87/87 [==============================] - 33s 379ms/step - loss: 0.3877 - accuracy: 0.9939 - get_f1: 0.9649 - val_loss: 1.6995 - val_accuracy: 0.3908 - val_get_f1: 0.2521\n",
            "Epoch 12/100\n",
            "87/87 [==============================] - 33s 379ms/step - loss: 0.2699 - accuracy: 0.9964 - get_f1: 0.9734 - val_loss: 0.5041 - val_accuracy: 0.9325 - val_get_f1: 0.7000\n",
            "Epoch 13/100\n",
            "87/87 [==============================] - 33s 379ms/step - loss: 0.2283 - accuracy: 0.9978 - get_f1: 0.9871 - val_loss: 0.3361 - val_accuracy: 0.9583 - val_get_f1: 0.8157\n",
            "Epoch 14/100\n",
            "87/87 [==============================] - 33s 381ms/step - loss: 0.2223 - accuracy: 0.9982 - get_f1: 0.9840 - val_loss: 0.2958 - val_accuracy: 0.9641 - val_get_f1: 0.7984\n",
            "Epoch 15/100\n",
            "87/87 [==============================] - 33s 381ms/step - loss: 0.2716 - accuracy: 0.9971 - get_f1: 0.9662 - val_loss: 0.3593 - val_accuracy: 0.9555 - val_get_f1: 0.8117\n",
            "Epoch 16/100\n",
            "87/87 [==============================] - 33s 381ms/step - loss: 0.1725 - accuracy: 0.9978 - get_f1: 0.9602 - val_loss: 0.2949 - val_accuracy: 0.9684 - val_get_f1: 0.8702\n",
            "Epoch 17/100\n",
            "87/87 [==============================] - 33s 381ms/step - loss: 0.1593 - accuracy: 0.9989 - get_f1: 0.9871 - val_loss: 0.2928 - val_accuracy: 0.9655 - val_get_f1: 0.8369\n",
            "Epoch 18/100\n",
            "87/87 [==============================] - 33s 379ms/step - loss: 0.1713 - accuracy: 0.9982 - get_f1: 0.9649 - val_loss: 0.2724 - val_accuracy: 0.9655 - val_get_f1: 0.8558\n",
            "Epoch 19/100\n",
            "87/87 [==============================] - 33s 379ms/step - loss: 0.1409 - accuracy: 0.9989 - get_f1: 0.9839 - val_loss: 0.2470 - val_accuracy: 0.9598 - val_get_f1: 0.7817\n",
            "Epoch 20/100\n",
            "87/87 [==============================] - 33s 379ms/step - loss: 0.1412 - accuracy: 0.9989 - get_f1: 0.9770 - val_loss: 0.2216 - val_accuracy: 0.9569 - val_get_f1: 0.7880\n",
            "Epoch 21/100\n",
            "87/87 [==============================] - 33s 382ms/step - loss: 0.1310 - accuracy: 1.0000 - get_f1: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9641 - val_get_f1: 0.8063\n",
            "Epoch 22/100\n",
            "87/87 [==============================] - 33s 381ms/step - loss: 0.1224 - accuracy: 0.9993 - get_f1: 0.9954 - val_loss: 0.2503 - val_accuracy: 0.9641 - val_get_f1: 0.7469\n",
            "Epoch 23/100\n",
            "87/87 [==============================] - 33s 381ms/step - loss: 0.1875 - accuracy: 0.9960 - get_f1: 0.9715 - val_loss: 0.2020 - val_accuracy: 0.9583 - val_get_f1: 0.7730\n",
            "Epoch 24/100\n",
            "87/87 [==============================] - 33s 380ms/step - loss: 0.1247 - accuracy: 0.9975 - get_f1: 0.9655 - val_loss: 0.2374 - val_accuracy: 0.9670 - val_get_f1: 0.8329\n",
            "Epoch 25/100\n",
            "87/87 [==============================] - 33s 382ms/step - loss: 0.1311 - accuracy: 0.9993 - get_f1: 0.9956 - val_loss: 0.2102 - val_accuracy: 0.9569 - val_get_f1: 0.7753\n",
            "Epoch 26/100\n",
            "87/87 [==============================] - 33s 383ms/step - loss: 0.1405 - accuracy: 0.9975 - get_f1: 0.9648 - val_loss: 0.1961 - val_accuracy: 0.9598 - val_get_f1: 0.6943\n",
            "Epoch 27/100\n",
            "87/87 [==============================] - 33s 382ms/step - loss: 0.1129 - accuracy: 1.0000 - get_f1: 0.9885 - val_loss: 0.1983 - val_accuracy: 0.9612 - val_get_f1: 0.7930\n",
            "Epoch 28/100\n",
            "87/87 [==============================] - 33s 384ms/step - loss: 0.1237 - accuracy: 0.9993 - get_f1: 0.9885 - val_loss: 0.2079 - val_accuracy: 0.9598 - val_get_f1: 0.7710\n",
            "Epoch 29/100\n",
            "87/87 [==============================] - 33s 380ms/step - loss: 0.1386 - accuracy: 0.9982 - get_f1: 0.9649 - val_loss: 0.3191 - val_accuracy: 0.9670 - val_get_f1: 0.8226\n",
            "Epoch 30/100\n",
            "87/87 [==============================] - 33s 379ms/step - loss: 0.1159 - accuracy: 1.0000 - get_f1: 0.9885 - val_loss: 0.2490 - val_accuracy: 0.9641 - val_get_f1: 0.8344\n",
            "Epoch 31/100\n",
            "87/87 [==============================] - 33s 382ms/step - loss: 0.1179 - accuracy: 0.9982 - get_f1: 0.9770 - val_loss: 0.2133 - val_accuracy: 0.9612 - val_get_f1: 0.8075\n",
            "Epoch 32/100\n",
            "87/87 [==============================] - 33s 380ms/step - loss: 0.1091 - accuracy: 0.9996 - get_f1: 0.9962 - val_loss: 0.2088 - val_accuracy: 0.9612 - val_get_f1: 0.8187\n",
            "Epoch 33/100\n",
            "87/87 [==============================] - 33s 381ms/step - loss: 0.1157 - accuracy: 0.9982 - get_f1: 0.9878 - val_loss: 0.4431 - val_accuracy: 0.9641 - val_get_f1: 0.8176\n",
            "Epoch 34/100\n",
            "87/87 [==============================] - 33s 382ms/step - loss: 0.1604 - accuracy: 0.9971 - get_f1: 0.9705 - val_loss: 0.2174 - val_accuracy: 0.9598 - val_get_f1: 0.7577\n",
            "Epoch 35/100\n",
            "87/87 [==============================] - 33s 381ms/step - loss: 0.1188 - accuracy: 0.9986 - get_f1: 0.9770 - val_loss: 0.2356 - val_accuracy: 0.9612 - val_get_f1: 0.8027\n",
            "Epoch 36/100\n",
            "87/87 [==============================] - 33s 381ms/step - loss: 0.1060 - accuracy: 1.0000 - get_f1: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9655 - val_get_f1: 0.8556\n",
            "Epoch 00036: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdrLBu-dCItY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93cf65d3-ca48-466e-fd32-38f2dcbda5cd"
      },
      "source": [
        "preds =  model.predict(X_val/255.0)\n",
        "predictions = []\n",
        "for i in preds:\n",
        "  if i[0] > 0.5:\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)\n",
        "\n",
        "#\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_val,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8536585365853657"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "eO2Y14sFYUc-",
        "outputId": "954e589c-50ef-47a7-b123-ebd623805996"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "sns.heatmap(confusion_matrix(y_val,predictions),annot=True,fmt=\".2f\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6696547080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTbhAJpaYjTq"
      },
      "source": [
        "#### **Final Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddMFnOj5YnVH",
        "outputId": "093a7600-4600-460b-b3ef-ae5da6991db7"
      },
      "source": [
        "preds = model.predict(test_pixel_data)\n",
        "#\n",
        "predictions = []\n",
        "for i in preds:\n",
        "  if i[0] > 0.5:\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)\n",
        "#\n",
        "result = pd.DataFrame(predictions,columns=['prediction'])\n",
        "#\n",
        "print(result.value_counts())\n",
        "#\n",
        "result.to_csv('ResNet50_full_trained.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction\n",
            "0             767\n",
            "1             103\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkJZRCu3ZOpX"
      },
      "source": [
        "#### **Resnet50 Dphi scores :89.75609756097562**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi5uSJALCJP7"
      },
      "source": [
        "#### **Grad-CAM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZaJWsWqCQTV"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lByhXxqwCZSz"
      },
      "source": [
        "#### **Function to display images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoAUOIdOCWNb"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "\t# convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSlOk2CnCkZr"
      },
      "source": [
        "##**Arguement Parser**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R534-qZlXuJo"
      },
      "source": [
        "********************************************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SElcqnhihDCq"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet152V2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypKCsVJQhOib"
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    conv_base = ResNet152V2(input_shape=(224,224,3), include_top=False, pooling='max',weights='imagenet')\n",
        "    model.add(conv_base)\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n",
        "    #model.add(BatchNormalization())\n",
        "    #model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n",
        "    #model.add(BatchNormalization())\n",
        "    #model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n",
        "    #model.add(BatchNormalization())\n",
        "    #model.add(Dense(1024, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    #for layer in model.layers:\n",
        "    #  layer.trainable = True\n",
        "    train_layers = [layer for layer in conv_base.layers[::-1][:5]]\n",
        "    \n",
        "    for layer in conv_base.layers:\n",
        "      if layer in train_layers:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy',get_f1])\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Us0Z--6hk6g",
        "outputId": "2030bb91-db7c-4046-f730-6a7d31b4ee8e"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet152v2 (Functional)     (None, 2048)              58331648  \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 62,538,241\n",
            "Trainable params: 62,390,401\n",
            "Non-trainable params: 147,840\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XxN2-9Shoua",
        "outputId": "0435b319-0fcb-4164-b70a-a4116a0fd107"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=87,\n",
        "                    epochs=100,\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps=22,\n",
        "                    callbacks=[cbs],\n",
        "                    class_weight={0:1,1:2})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 653.4847 - accuracy: 0.9062 - get_f1: 0.6157 - val_loss: 493.6855 - val_accuracy: 0.8865 - val_get_f1: 0.0281\n",
            "Epoch 2/100\n",
            "87/87 [==============================] - 71s 814ms/step - loss: 365.5524 - accuracy: 0.9687 - get_f1: 0.8531 - val_loss: 249.1924 - val_accuracy: 0.9138 - val_get_f1: 0.3386\n",
            "Epoch 3/100\n",
            "87/87 [==============================] - 71s 817ms/step - loss: 163.1143 - accuracy: 0.9856 - get_f1: 0.9270 - val_loss: 89.1624 - val_accuracy: 0.9583 - val_get_f1: 0.7617\n",
            "Epoch 4/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 43.7298 - accuracy: 0.9978 - get_f1: 0.9895 - val_loss: 10.8226 - val_accuracy: 0.9626 - val_get_f1: 0.7967\n",
            "Epoch 5/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 2.8789 - accuracy: 0.9885 - get_f1: 0.9439 - val_loss: 0.9052 - val_accuracy: 0.9339 - val_get_f1: 0.5628\n",
            "Epoch 6/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.9553 - accuracy: 0.9795 - get_f1: 0.8877 - val_loss: 0.9097 - val_accuracy: 0.9425 - val_get_f1: 0.6515\n",
            "Epoch 7/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.6717 - accuracy: 0.9824 - get_f1: 0.9026 - val_loss: 0.7988 - val_accuracy: 0.9612 - val_get_f1: 0.8003\n",
            "Epoch 8/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.6299 - accuracy: 0.9867 - get_f1: 0.9329 - val_loss: 0.6623 - val_accuracy: 0.9684 - val_get_f1: 0.8191\n",
            "Epoch 9/100\n",
            "87/87 [==============================] - 71s 815ms/step - loss: 0.6086 - accuracy: 0.9874 - get_f1: 0.9301 - val_loss: 0.5758 - val_accuracy: 0.9626 - val_get_f1: 0.8105\n",
            "Epoch 10/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.6394 - accuracy: 0.9828 - get_f1: 0.9090 - val_loss: 0.5662 - val_accuracy: 0.9583 - val_get_f1: 0.7819\n",
            "Epoch 11/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.6105 - accuracy: 0.9878 - get_f1: 0.9184 - val_loss: 0.6379 - val_accuracy: 0.9612 - val_get_f1: 0.8090\n",
            "Epoch 12/100\n",
            "87/87 [==============================] - 71s 815ms/step - loss: 0.4978 - accuracy: 0.9842 - get_f1: 0.9210 - val_loss: 0.4494 - val_accuracy: 0.9569 - val_get_f1: 0.7167\n",
            "Epoch 13/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.4905 - accuracy: 0.9903 - get_f1: 0.9349 - val_loss: 0.4505 - val_accuracy: 0.8980 - val_get_f1: 0.1990\n",
            "Epoch 14/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.4158 - accuracy: 0.9896 - get_f1: 0.9536 - val_loss: 0.3614 - val_accuracy: 0.9612 - val_get_f1: 0.7645\n",
            "Epoch 15/100\n",
            "87/87 [==============================] - 71s 817ms/step - loss: 0.4087 - accuracy: 0.9903 - get_f1: 0.9350 - val_loss: 0.3856 - val_accuracy: 0.9655 - val_get_f1: 0.7744\n",
            "Epoch 16/100\n",
            "87/87 [==============================] - 71s 817ms/step - loss: 0.3904 - accuracy: 0.9950 - get_f1: 0.9666 - val_loss: 0.3873 - val_accuracy: 0.9641 - val_get_f1: 0.7964\n",
            "Epoch 17/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.3910 - accuracy: 0.9914 - get_f1: 0.9492 - val_loss: 0.4142 - val_accuracy: 0.9612 - val_get_f1: 0.7869\n",
            "Epoch 18/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.3734 - accuracy: 0.9925 - get_f1: 0.9707 - val_loss: 0.3972 - val_accuracy: 0.9612 - val_get_f1: 0.8038\n",
            "Epoch 19/100\n",
            "87/87 [==============================] - 71s 820ms/step - loss: 0.3892 - accuracy: 0.9853 - get_f1: 0.9312 - val_loss: 0.3601 - val_accuracy: 0.9655 - val_get_f1: 0.8005\n",
            "Epoch 20/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.3832 - accuracy: 0.9932 - get_f1: 0.9648 - val_loss: 0.4627 - val_accuracy: 0.9641 - val_get_f1: 0.8605\n",
            "Epoch 21/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.4028 - accuracy: 0.9921 - get_f1: 0.9602 - val_loss: 0.3824 - val_accuracy: 0.9655 - val_get_f1: 0.7597\n",
            "Epoch 22/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.3819 - accuracy: 0.9953 - get_f1: 0.9635 - val_loss: 0.3781 - val_accuracy: 0.9612 - val_get_f1: 0.8404\n",
            "Epoch 23/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.3695 - accuracy: 0.9939 - get_f1: 0.9645 - val_loss: 0.3609 - val_accuracy: 0.9641 - val_get_f1: 0.7322\n",
            "Epoch 24/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.3760 - accuracy: 0.9899 - get_f1: 0.9433 - val_loss: 0.4328 - val_accuracy: 0.9641 - val_get_f1: 0.7746\n",
            "Epoch 25/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.3727 - accuracy: 0.9921 - get_f1: 0.9728 - val_loss: 0.3745 - val_accuracy: 0.9626 - val_get_f1: 0.8075\n",
            "Epoch 26/100\n",
            "87/87 [==============================] - 71s 821ms/step - loss: 0.3710 - accuracy: 0.9943 - get_f1: 0.9764 - val_loss: 0.3716 - val_accuracy: 0.9612 - val_get_f1: 0.8327\n",
            "Epoch 27/100\n",
            "87/87 [==============================] - 71s 817ms/step - loss: 0.3559 - accuracy: 0.9953 - get_f1: 0.9676 - val_loss: 0.4236 - val_accuracy: 0.9655 - val_get_f1: 0.8114\n",
            "Epoch 28/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.3673 - accuracy: 0.9975 - get_f1: 0.9655 - val_loss: 0.3982 - val_accuracy: 0.9641 - val_get_f1: 0.8539\n",
            "Epoch 29/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.3540 - accuracy: 0.9968 - get_f1: 0.9862 - val_loss: 0.3464 - val_accuracy: 0.9641 - val_get_f1: 0.7569\n",
            "Epoch 30/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.3625 - accuracy: 0.9935 - get_f1: 0.9788 - val_loss: 0.4916 - val_accuracy: 0.9670 - val_get_f1: 0.8560\n",
            "Epoch 31/100\n",
            "87/87 [==============================] - 71s 820ms/step - loss: 0.3604 - accuracy: 0.9943 - get_f1: 0.9762 - val_loss: 0.3639 - val_accuracy: 0.9641 - val_get_f1: 0.8155\n",
            "Epoch 32/100\n",
            "87/87 [==============================] - 71s 817ms/step - loss: 0.3589 - accuracy: 0.9950 - get_f1: 0.9713 - val_loss: 0.3780 - val_accuracy: 0.9684 - val_get_f1: 0.7971\n",
            "Epoch 33/100\n",
            "87/87 [==============================] - 71s 817ms/step - loss: 0.3614 - accuracy: 0.9928 - get_f1: 0.9544 - val_loss: 0.4625 - val_accuracy: 0.9598 - val_get_f1: 0.8072\n",
            "Epoch 34/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.3506 - accuracy: 0.9943 - get_f1: 0.9749 - val_loss: 0.5110 - val_accuracy: 0.9626 - val_get_f1: 0.8092\n",
            "Epoch 35/100\n",
            "87/87 [==============================] - 71s 817ms/step - loss: 0.3606 - accuracy: 0.9960 - get_f1: 0.9670 - val_loss: 0.3645 - val_accuracy: 0.9655 - val_get_f1: 0.8191\n",
            "Epoch 36/100\n",
            "87/87 [==============================] - 71s 820ms/step - loss: 0.3414 - accuracy: 0.9986 - get_f1: 0.9939 - val_loss: 0.3468 - val_accuracy: 0.9612 - val_get_f1: 0.7286\n",
            "Epoch 37/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.3428 - accuracy: 0.9989 - get_f1: 0.9969 - val_loss: 0.3362 - val_accuracy: 0.9612 - val_get_f1: 0.8414\n",
            "Epoch 38/100\n",
            "87/87 [==============================] - 71s 820ms/step - loss: 0.3589 - accuracy: 0.9921 - get_f1: 0.9378 - val_loss: 0.3756 - val_accuracy: 0.9598 - val_get_f1: 0.8022\n",
            "Epoch 39/100\n",
            "87/87 [==============================] - 71s 820ms/step - loss: 0.3571 - accuracy: 0.9932 - get_f1: 0.9679 - val_loss: 0.4102 - val_accuracy: 0.9483 - val_get_f1: 0.7758\n",
            "Epoch 40/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.3711 - accuracy: 0.9892 - get_f1: 0.9601 - val_loss: 0.4168 - val_accuracy: 0.9612 - val_get_f1: 0.7391\n",
            "Epoch 41/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.3555 - accuracy: 0.9921 - get_f1: 0.9588 - val_loss: 0.3514 - val_accuracy: 0.9641 - val_get_f1: 0.8028\n",
            "Epoch 42/100\n",
            "87/87 [==============================] - 71s 818ms/step - loss: 0.3487 - accuracy: 0.9946 - get_f1: 0.9459 - val_loss: 0.3675 - val_accuracy: 0.9684 - val_get_f1: 0.8567\n",
            "Epoch 43/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.3543 - accuracy: 0.9943 - get_f1: 0.9673 - val_loss: 0.3670 - val_accuracy: 0.9612 - val_get_f1: 0.6848\n",
            "Epoch 44/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.3494 - accuracy: 0.9921 - get_f1: 0.9519 - val_loss: 0.3535 - val_accuracy: 0.9641 - val_get_f1: 0.8263\n",
            "Epoch 45/100\n",
            "87/87 [==============================] - 71s 819ms/step - loss: 0.3264 - accuracy: 0.9968 - get_f1: 0.9785 - val_loss: 0.3369 - val_accuracy: 0.9655 - val_get_f1: 0.8440\n",
            "Epoch 46/100\n",
            "87/87 [==============================] - 71s 820ms/step - loss: 0.3381 - accuracy: 0.9975 - get_f1: 0.9480 - val_loss: 0.3690 - val_accuracy: 0.9655 - val_get_f1: 0.7881\n",
            "Epoch 47/100\n",
            "87/87 [==============================] - 71s 820ms/step - loss: 0.3531 - accuracy: 0.9946 - get_f1: 0.9336 - val_loss: 0.3805 - val_accuracy: 0.9655 - val_get_f1: 0.8275\n",
            "Epoch 00047: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAFauyhuvLy9",
        "outputId": "041f1043-a8ba-438e-d1a4-c4b1edffa098"
      },
      "source": [
        "preds =  model.predict(X_val/255.0)\n",
        "predictions = []\n",
        "for i in preds:\n",
        "  if i[0] > 0.5:\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)\n",
        "\n",
        "#\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_val,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8481012658227849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFghJAsZvTvB",
        "outputId": "f6aafa0d-b329-471a-ed27-3899eb9103c1"
      },
      "source": [
        "preds = model.predict(test_pixel_data)\n",
        "#\n",
        "predictions = []\n",
        "for i in preds:\n",
        "  if i[0] > 0.5:\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)\n",
        "#\n",
        "result = pd.DataFrame(predictions,columns=['prediction'])\n",
        "#\n",
        "print(result.value_counts())\n",
        "#\n",
        "result.to_csv('ResNet152V2_full_trained.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction\n",
            "0             764\n",
            "1             106\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SOp9Kd7vqld"
      },
      "source": [
        "#### **Dphi Score 87.5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD6y0Z2iwXob"
      },
      "source": [
        "####**DenseNet169**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05qi6UUfwvtU"
      },
      "source": [
        "******************************************************************************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUhGIMdjV8Sv"
      },
      "source": [
        "from tensorflow.keras.applications import DenseNet169"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDuQRL6Q01AY"
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    conv_base = DenseNet169(input_shape=(224,224,3), include_top=False, pooling='max',weights='imagenet')\n",
        "    model.add(conv_base)\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n",
        "    \"\"\"\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(1024, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
        "    model.add(BatchNormalization())\"\"\"\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    for layer in model.layers:\n",
        "      layer.trainable = True\n",
        "    #train_layers = [layer for layer in conv_base.layers[::-1][:5]]\n",
        "    \"\"\"\n",
        "    for layer in conv_base.layers:\n",
        "      if layer in train_layers:\n",
        "        layer.trainable = True\n",
        "    \"\"\"\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy',get_f1])\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekmJ1QQTW3lX",
        "outputId": "810d5dda-856e-484c-8ea4-f03a3c28488a"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 4s 0us/step\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet169 (Functional)     (None, 1664)              12642880  \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1664)              6656      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2048)              3409920   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 16,061,505\n",
            "Trainable params: 15,899,777\n",
            "Non-trainable params: 161,728\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmBQvrBNXAf5",
        "outputId": "22432bb8-d700-4a57-a83c-74c594971509"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=87,\n",
        "                    epochs=100,\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps=22,\n",
        "                    callbacks=[cbs],\n",
        "                    class_weight={0:1,1:2})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "87/87 [==============================] - 80s 920ms/step - loss: 563.8148 - accuracy: 0.9041 - get_f1: 0.6890 - val_loss: 432.0593 - val_accuracy: 0.9239 - val_get_f1: 0.5201\n",
            "Epoch 2/100\n",
            "87/87 [==============================] - 77s 884ms/step - loss: 325.6119 - accuracy: 0.9813 - get_f1: 0.9032 - val_loss: 228.2778 - val_accuracy: 0.9353 - val_get_f1: 0.6797\n",
            "Epoch 3/100\n",
            "87/87 [==============================] - 77s 883ms/step - loss: 154.5846 - accuracy: 0.9943 - get_f1: 0.9469 - val_loss: 90.5258 - val_accuracy: 0.9023 - val_get_f1: 0.6573\n",
            "Epoch 4/100\n",
            "87/87 [==============================] - 77s 887ms/step - loss: 48.5107 - accuracy: 0.9914 - get_f1: 0.9369 - val_loss: 16.4518 - val_accuracy: 0.9339 - val_get_f1: 0.7033\n",
            "Epoch 5/100\n",
            "87/87 [==============================] - 77s 886ms/step - loss: 4.8200 - accuracy: 0.9896 - get_f1: 0.9447 - val_loss: 0.9422 - val_accuracy: 0.9095 - val_get_f1: 0.6635\n",
            "Epoch 6/100\n",
            "87/87 [==============================] - 77s 887ms/step - loss: 0.8228 - accuracy: 0.9856 - get_f1: 0.9291 - val_loss: 0.8615 - val_accuracy: 0.9353 - val_get_f1: 0.7478\n",
            "Epoch 7/100\n",
            "87/87 [==============================] - 77s 885ms/step - loss: 0.7989 - accuracy: 0.9842 - get_f1: 0.9120 - val_loss: 0.7865 - val_accuracy: 0.9454 - val_get_f1: 0.7112\n",
            "Epoch 8/100\n",
            "87/87 [==============================] - 77s 882ms/step - loss: 0.7802 - accuracy: 0.9756 - get_f1: 0.8672 - val_loss: 0.8552 - val_accuracy: 0.9253 - val_get_f1: 0.6926\n",
            "Epoch 9/100\n",
            "87/87 [==============================] - 77s 882ms/step - loss: 0.7941 - accuracy: 0.9720 - get_f1: 0.8314 - val_loss: 0.8363 - val_accuracy: 0.9511 - val_get_f1: 0.7723\n",
            "Epoch 10/100\n",
            "87/87 [==============================] - 77s 884ms/step - loss: 0.4160 - accuracy: 0.9845 - get_f1: 0.9336 - val_loss: 0.3687 - val_accuracy: 0.9540 - val_get_f1: 0.7634\n",
            "Epoch 11/100\n",
            "87/87 [==============================] - 77s 884ms/step - loss: 0.3508 - accuracy: 0.9932 - get_f1: 0.9632 - val_loss: 0.3896 - val_accuracy: 0.9526 - val_get_f1: 0.8098\n",
            "Epoch 12/100\n",
            "87/87 [==============================] - 77s 882ms/step - loss: 0.3493 - accuracy: 0.9928 - get_f1: 0.9472 - val_loss: 0.3758 - val_accuracy: 0.9540 - val_get_f1: 0.7734\n",
            "Epoch 13/100\n",
            "87/87 [==============================] - 77s 882ms/step - loss: 0.3316 - accuracy: 0.9982 - get_f1: 0.9871 - val_loss: 0.3696 - val_accuracy: 0.9555 - val_get_f1: 0.7818\n",
            "Epoch 14/100\n",
            "87/87 [==============================] - 77s 884ms/step - loss: 0.3260 - accuracy: 0.9960 - get_f1: 0.9885 - val_loss: 0.3620 - val_accuracy: 0.9555 - val_get_f1: 0.7968\n",
            "Epoch 15/100\n",
            "87/87 [==============================] - 77s 885ms/step - loss: 0.3252 - accuracy: 0.9989 - get_f1: 0.9885 - val_loss: 0.3370 - val_accuracy: 0.9569 - val_get_f1: 0.7856\n",
            "Epoch 16/100\n",
            "87/87 [==============================] - 77s 883ms/step - loss: 0.3302 - accuracy: 0.9971 - get_f1: 0.9816 - val_loss: 0.3528 - val_accuracy: 0.9555 - val_get_f1: 0.7753\n",
            "Epoch 17/100\n",
            "87/87 [==============================] - 77s 884ms/step - loss: 0.3268 - accuracy: 0.9950 - get_f1: 0.9758 - val_loss: 0.3517 - val_accuracy: 0.9555 - val_get_f1: 0.7994\n",
            "Epoch 18/100\n",
            "87/87 [==============================] - 77s 884ms/step - loss: 0.3261 - accuracy: 0.9975 - get_f1: 0.9743 - val_loss: 0.3449 - val_accuracy: 0.9555 - val_get_f1: 0.7465\n",
            "Epoch 19/100\n",
            "87/87 [==============================] - 77s 883ms/step - loss: 0.3194 - accuracy: 0.9993 - get_f1: 0.9876 - val_loss: 0.3517 - val_accuracy: 0.9540 - val_get_f1: 0.7429\n",
            "Epoch 00019: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgIKuX0IwzET"
      },
      "source": [
        "******************************************************************************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VStMxBgGjBhK"
      },
      "source": [
        "#### **Evaluation of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF9MUW5egKE0",
        "outputId": "ac070e2b-1cb6-4deb-9d9f-b657689b6f1a"
      },
      "source": [
        "preds =  model.predict(X_val/255.0)\n",
        "predictions = []\n",
        "for i in preds:\n",
        "  if i[0] >= 0.5:\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)\n",
        "\n",
        "#\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_val,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7922077922077922"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "fF5htOyo4vFP",
        "outputId": "28b222d5-4fd7-4e57-abc9-036ee8b63c29"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "sns.heatmap(confusion_matrix(y_val,predictions),annot=True,fmt=\".2f\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f44553abcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhMIjitDjNRq"
      },
      "source": [
        "#### **Predict on the resultset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHFtgxq3jTKo"
      },
      "source": [
        "preds = model.predict(test_pixel_data)\n",
        "#\n",
        "predictions = []\n",
        "for i in preds:\n",
        "  if i[0] >= 0.5:\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)\n",
        "#\n",
        "result = pd.DataFrame(predictions,columns=['prediction'])\n",
        "#\n",
        "result.value_counts()\n",
        "#\n",
        "result.to_csv('denseNet169_full_trained1.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC2RQXjS5HZJ",
        "outputId": "68a2aa5a-6832-4ccc-cce7-860a343d14ef"
      },
      "source": [
        "result.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "prediction\n",
              "0             777\n",
              "1              93\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh3a-_E95Z-8"
      },
      "source": [
        "#### **Dphi Scores :86.91588785046729 for Densenet169**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3WVAyJm45kG",
        "outputId": "7eeae051-9992-41ea-b072-4921873d218d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYakb9ty40i-",
        "outputId": "c7a18679-fbd6-4a1f-bf28-fd658406bdd8"
      },
      "source": [
        "\n",
        "model.save(\"/content/drive/MyDrive/AV_Hack/resnet169\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/AV_Hack/resnet169/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssQFhHuE5eNn"
      },
      "source": [
        "\"\"\"from tensorflow import keras\n",
        "model = keras.models.load_model('path/to/location')\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPJbZ8mPRFuq"
      },
      "source": [
        "#### **Gradient weighted Class Activation Map**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuydkgkHRJwp"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVE98KbeRNSf"
      },
      "source": [
        "#### **Function to display images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UZh0uaTRSfP"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "\t# convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dukdyZjHRemx"
      },
      "source": [
        "#### **Arguement Parser**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "uqPgtlEBpBDE",
        "outputId": "2bf9c0a9-779d-48ed-927c-5f418a75d612"
      },
      "source": [
        "train = pd.read_csv(\"/content/content/covid_image_data/Training_set_covid.csv\")\n",
        "train[train['label']==1].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Image_12.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Image_15.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Image_24.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Image_36.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        filename  label\n",
              "0    Image_1.jpg      1\n",
              "11  Image_12.jpg      1\n",
              "14  Image_15.jpg      1\n",
              "23  Image_24.jpg      1\n",
              "35  Image_36.jpg      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_BHmgiroWYc"
      },
      "source": [
        "args = {\n",
        "\t\"image\": \"/content/content/covid_image_data/train/Image_1.jpg\",\n",
        "\t\"model\": \"resnet\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkCGAOU6wb_H"
      },
      "source": [
        "# load the original image from disk (in OpenCV format) and then\n",
        "# resize the image to its target dimensions\n",
        "orig = cv2.imread(args[\"image\"])\n",
        "resized = cv2.resize(orig, (224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iusR69zjpTFz"
      },
      "source": [
        "# load the input image from disk (in Keras/TensorFlow format) and\n",
        "# preprocess it\n",
        "image = load_img(args[\"image\"], target_size=(224, 224))\n",
        "image = img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "image = imagenet_utils.preprocess_input(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ_r5Yj4xm7t",
        "outputId": "da47acab-32e4-40eb-da10-441904659fbd"
      },
      "source": [
        "image.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFyoXDq1wwzp"
      },
      "source": [
        "preds = model.predict(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXLTKzqswyVt",
        "outputId": "0b13c353-3fcf-412a-f2a5-3dddfacb0639"
      },
      "source": [
        "preds[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuMI64WypdPk",
        "outputId": "4debecf6-08ba-47df-fc3e-69edba405829"
      },
      "source": [
        "# use the network to make predictions on the input image and find\n",
        "# the class label index with the largest corresponding probability\n",
        "preds = model.predict(image)\n",
        "i = preds[0][0]\n",
        "\n",
        "# decode the ImageNet predictions to obtain the human-readable label\n",
        "if i == 1:\n",
        "  label = \"Covid19 Infected\"\n",
        "else:\n",
        "  label = \"Covid19 Not Infected\"\n",
        "label = \"{}: {:.2f}%\".format(label, preds[0][0]* 100)\n",
        "print(\"[INFO] {}\".format(label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Covid19 Infected: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4UO4K5-xz-H",
        "outputId": "949d5995-6c90-4a56-c136-94ca302e1d6a"
      },
      "source": [
        "for layer in reversed(model.layers):\n",
        "  print(layer.name)\n",
        "  print(layer.output_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dense_6\n",
            "(None, 1)\n",
            "dense_5\n",
            "(None, 2048)\n",
            "batch_normalization_5\n",
            "(None, 2048)\n",
            "resnet152v2\n",
            "(None, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G_nBVatqAg8"
      },
      "source": [
        "class GradCAM:\n",
        "\tdef __init__(self, model, classIdx, layerName=None):\n",
        "\t\t# store the model, the class index used to measure the class\n",
        "\t\t# activation map, and the layer to be used when visualizing\n",
        "\t\t# the class activation map\n",
        "\t\tself.model = model\n",
        "\t\tself.classIdx = classIdx\n",
        "\t\tself.layerName = layerName\n",
        "\n",
        "\t\t# if the layer name is None, attempt to automatically find\n",
        "\t\t# the target output layer\n",
        "\t\tif self.layerName is None:\n",
        "\t\t\tself.layerName = self.find_target_layer()\n",
        "\n",
        "\tdef find_target_layer(self):\n",
        "\t\t# attempt to find the final convolutional layer in the network\n",
        "\t\t# by looping over the layers of the network in reverse order\n",
        "\t\tfor layer in reversed(self.model.layers):\n",
        "\t\t\t# check to see if the layer has a 4D output\n",
        "\t\t\tif len(layer.output_shape) == 4:\n",
        "\t\t\t\treturn layer.name\n",
        "\n",
        "\t\t# otherwise, we could not find a 4D layer so the GradCAM\n",
        "\t\t# algorithm cannot be applied\n",
        "\t\traise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
        "\n",
        "\tdef compute_heatmap(self, image, eps=1e-8):\n",
        "\t\t# construct our gradient model by supplying (1) the inputs\n",
        "\t\t# to our pre-trained model, (2) the output of the (presumably)\n",
        "\t\t# final 4D layer in the network, and (3) the output of the\n",
        "\t\t# softmax activations from the model\n",
        "\t\tgradModel = Model(\n",
        "\t\t\tinputs=[self.model.inputs],\n",
        "\t\t\toutputs=[self.model.get_layer(self.layerName).output, \n",
        "\t\t\t\tself.model.output])\n",
        "\n",
        "\t\t# record operations for automatic differentiation\n",
        "\t\twith tf.GradientTape() as tape:\n",
        "\t\t\t# cast the image tensor to a float-32 data type, pass the\n",
        "\t\t\t# image through the gradient model, and grab the loss\n",
        "\t\t\t# associated with the specific class index\n",
        "\t\t\tinputs = tf.cast(image, tf.float32)\n",
        "\t\t\t(convOutputs, predictions) = gradModel(inputs)\n",
        "\t\t\tloss = predictions[:, self.classIdx]\n",
        "\n",
        "\t\t# use automatic differentiation to compute the gradients\n",
        "\t\tgrads = tape.gradient(loss, convOutputs)\n",
        "\n",
        "\t\t# compute the guided gradients\n",
        "\t\tcastConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
        "\t\tcastGrads = tf.cast(grads > 0, \"float32\")\n",
        "\t\tguidedGrads = castConvOutputs * castGrads * grads\n",
        "\n",
        "\t\t# the convolution and guided gradients have a batch dimension\n",
        "\t\t# (which we don't need) so let's grab the volume itself and\n",
        "\t\t# discard the batch\n",
        "\t\tconvOutputs = convOutputs[0]\n",
        "\t\tguidedGrads = guidedGrads[0]\n",
        "\n",
        "\t\t# compute the average of the gradient values, and using them\n",
        "\t\t# as weights, compute the ponderation of the filters with\n",
        "\t\t# respect to the weights\n",
        "\t\tweights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
        "\t\tcam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
        "\n",
        "\t\t# grab the spatial dimensions of the input image and resize\n",
        "\t\t# the output class activation map to match the input image\n",
        "\t\t# dimensions\n",
        "\t\t(w, h) = (image.shape[2], image.shape[1])\n",
        "\t\theatmap = cv2.resize(cam.numpy(), (w, h))\n",
        "\n",
        "\t\t# normalize the heatmap such that all values lie in the range\n",
        "\t\t# [0, 1], scale the resulting values to the range [0, 255],\n",
        "\t\t# and then convert to an unsigned 8-bit integer\n",
        "\t\tnumer = heatmap - np.min(heatmap)\n",
        "\t\tdenom = (heatmap.max() - heatmap.min()) + eps\n",
        "\t\theatmap = numer / denom\n",
        "\t\theatmap = (heatmap * 255).astype(\"uint8\")\n",
        "\n",
        "\t\t# return the resulting heatmap to the calling function\n",
        "\t\treturn heatmap\n",
        "\n",
        "\tdef overlay_heatmap(self, heatmap, image, alpha=0.5,\n",
        "\t\tcolormap=cv2.COLORMAP_VIRIDIS):\n",
        "\t\t# apply the supplied color map to the heatmap and then\n",
        "\t\t# overlay the heatmap on the input image\n",
        "\t\theatmap = cv2.applyColorMap(heatmap, colormap)\n",
        "\t\toutput = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
        "\n",
        "\t\t# return a 2-tuple of the color mapped heatmap and the output,\n",
        "\t\t# overlaid image\n",
        "\t\treturn (heatmap, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "TZDN-TD_pkZJ",
        "outputId": "2b0e4199-4afe-4f35-8d55-0a98442d81ff"
      },
      "source": [
        "# initialize our gradient class activation map and build the heatmap\n",
        "cam = GradCAM(model, i)\n",
        "heatmap = cam.compute_heatmap(image)\n",
        "\n",
        "# resize the resulting heatmap to the original input image dimensions\n",
        "# and then overlay heatmap on top of the image\n",
        "heatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n",
        "(heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-a13a175c440b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# initialize our gradient class activation map and build the heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradCAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# resize the resulting heatmap to the original input image dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-baa356b8a420>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, classIdx, layerName)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;31m# the target output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayerName\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayerName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_target_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfind_target_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-baa356b8a420>\u001b[0m in \u001b[0;36mfind_target_layer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# otherwise, we could not find a 4D layer so the GradCAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;31m# algorithm cannot be applied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not find 4D layer. Cannot apply GradCAM.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Could not find 4D layer. Cannot apply GradCAM."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EutAwB-DpoZM"
      },
      "source": [
        "# draw the predicted label on the output image\n",
        "cv2.rectangle(output, (0, 0), (340, 40), (0, 0, 0), -1)\n",
        "cv2.putText(output, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t0.8, (255, 255, 255), 2)\n",
        "\n",
        "# display the original image and resulting heatmap and output image\n",
        "# to our screen\n",
        "output = np.vstack([orig, heatmap, output])\n",
        "output = imutils.resize(output, height=700)\n",
        "plt_imshow(\"Output\", output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh3gKGcI5o5R"
      },
      "source": [
        "#### **Keras Model Selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E_Wyp5gRdQq"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set batch size for training and validation\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt4UmG3f54qP"
      },
      "source": [
        "# List all available models\n",
        "model_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UkWaOnC57sF",
        "outputId": "80fd881d-9554-4047-aef5-472ffb68e3c7"
      },
      "source": [
        "model_dictionary "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DenseNet121': <function tensorflow.python.keras.applications.densenet.DenseNet121>,\n",
              " 'DenseNet169': <function tensorflow.python.keras.applications.densenet.DenseNet169>,\n",
              " 'DenseNet201': <function tensorflow.python.keras.applications.densenet.DenseNet201>,\n",
              " 'EfficientNetB0': <function tensorflow.python.keras.applications.efficientnet.EfficientNetB0>,\n",
              " 'EfficientNetB1': <function tensorflow.python.keras.applications.efficientnet.EfficientNetB1>,\n",
              " 'EfficientNetB2': <function tensorflow.python.keras.applications.efficientnet.EfficientNetB2>,\n",
              " 'EfficientNetB3': <function tensorflow.python.keras.applications.efficientnet.EfficientNetB3>,\n",
              " 'EfficientNetB4': <function tensorflow.python.keras.applications.efficientnet.EfficientNetB4>,\n",
              " 'EfficientNetB5': <function tensorflow.python.keras.applications.efficientnet.EfficientNetB5>,\n",
              " 'EfficientNetB6': <function tensorflow.python.keras.applications.efficientnet.EfficientNetB6>,\n",
              " 'EfficientNetB7': <function tensorflow.python.keras.applications.efficientnet.EfficientNetB7>,\n",
              " 'InceptionResNetV2': <function tensorflow.python.keras.applications.inception_resnet_v2.InceptionResNetV2>,\n",
              " 'InceptionV3': <function tensorflow.python.keras.applications.inception_v3.InceptionV3>,\n",
              " 'MobileNet': <function tensorflow.python.keras.applications.mobilenet.MobileNet>,\n",
              " 'MobileNetV2': <function tensorflow.python.keras.applications.mobilenet_v2.MobileNetV2>,\n",
              " 'NASNetLarge': <function tensorflow.python.keras.applications.nasnet.NASNetLarge>,\n",
              " 'NASNetMobile': <function tensorflow.python.keras.applications.nasnet.NASNetMobile>,\n",
              " 'ResNet101': <function tensorflow.python.keras.applications.resnet.ResNet101>,\n",
              " 'ResNet101V2': <function tensorflow.python.keras.applications.resnet_v2.ResNet101V2>,\n",
              " 'ResNet152': <function tensorflow.python.keras.applications.resnet.ResNet152>,\n",
              " 'ResNet152V2': <function tensorflow.python.keras.applications.resnet_v2.ResNet152V2>,\n",
              " 'ResNet50': <function tensorflow.python.keras.applications.resnet.ResNet50>,\n",
              " 'ResNet50V2': <function tensorflow.python.keras.applications.resnet_v2.ResNet50V2>,\n",
              " 'VGG16': <function tensorflow.python.keras.applications.vgg16.VGG16>,\n",
              " 'VGG19': <function tensorflow.python.keras.applications.vgg19.VGG19>,\n",
              " 'Xception': <function tensorflow.python.keras.applications.xception.Xception>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUOlacCw8b1W",
        "outputId": "72af1126-a072-4a4d-b233-c670e28b6ae2"
      },
      "source": [
        "int(num_train/batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VggdVg076sAw",
        "outputId": "1aa9fd61-46dd-4123-f41e-b031fdf27153"
      },
      "source": [
        "# Loop over each model available in Keras\n",
        "# Number of training examples and labels\n",
        "num_train = len(list(X_train))\n",
        "num_validation = len(list(X_val))\n",
        "num_classes = 1\n",
        "num_iterations = int(num_train/batch_size)\n",
        "\n",
        "model_benchmarks = {'model_name': [], 'num_model_params': [], 'validation_accuracy': []}\n",
        "for model_name, model in tqdm(model_dictionary.items()):\n",
        "    # Special handling for \"NASNetLarge\" since it requires input images with size (331,331)\n",
        "    if model_name != 'NASNetLarge':\n",
        "        input_shape=(224,224,3)\n",
        "        train_processed = X_train\n",
        "        validation_processed = X_val\n",
        "\n",
        "    # load the pre-trained model with global average pooling as the last layer and freeze the model weights\n",
        "        pre_trained_model = model(include_top=False, pooling='avg', input_shape=input_shape)\n",
        "        pre_trained_model.trainable = False\n",
        "\n",
        "    # custom modifications on top of pre-trained model\n",
        "        clf_model = tf.keras.models.Sequential()\n",
        "        clf_model.add(pre_trained_model)\n",
        "        clf_model.add(tf.keras.layers.Dense(num_classes, activation='sigmoid'))\n",
        "        clf_model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        history = clf_model.fit(train_generator,\n",
        "                                epochs=3, \n",
        "                                validation_data=val_generator, \n",
        "                                steps_per_epoch=num_iterations)\n",
        "\n",
        "    # Calculate all relevant metrics\n",
        "        model_benchmarks['model_name'].append(model_name)\n",
        "        model_benchmarks['num_model_params'].append(pre_trained_model.count_params())\n",
        "        model_benchmarks['validation_accuracy'].append(history.history['val_accuracy'][-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "86/86 [==============================] - 13s 150ms/step - loss: 0.3118 - accuracy: 0.8753 - val_loss: 0.2814 - val_accuracy: 0.8908\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 10s 113ms/step - loss: 0.2372 - accuracy: 0.8975 - val_loss: 0.2328 - val_accuracy: 0.8937\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 10s 114ms/step - loss: 0.2034 - accuracy: 0.9088 - val_loss: 0.2195 - val_accuracy: 0.8994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  4%|         | 1/26 [00:49<20:29, 49.18s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 14s 169ms/step - loss: 0.2750 - accuracy: 0.8884 - val_loss: 0.2263 - val_accuracy: 0.8994\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 12s 138ms/step - loss: 0.2064 - accuracy: 0.9077 - val_loss: 0.1920 - val_accuracy: 0.9210\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 12s 138ms/step - loss: 0.1761 - accuracy: 0.9226 - val_loss: 0.1940 - val_accuracy: 0.9325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  8%|         | 2/26 [01:40<19:57, 49.90s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74842112/74836368 [==============================] - 1s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 18s 212ms/step - loss: 0.2951 - accuracy: 0.8862 - val_loss: 0.2508 - val_accuracy: 0.8951\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 15s 175ms/step - loss: 0.2234 - accuracy: 0.9040 - val_loss: 0.2084 - val_accuracy: 0.8994\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 15s 177ms/step - loss: 0.1908 - accuracy: 0.9186 - val_loss: 0.1898 - val_accuracy: 0.9124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 12%|        | 3/26 [02:45<20:51, 54.43s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 8s 94ms/step - loss: 0.3827 - accuracy: 0.8771 - val_loss: 0.3602 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 7s 77ms/step - loss: 0.3643 - accuracy: 0.8833 - val_loss: 0.3595 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 7s 77ms/step - loss: 0.3643 - accuracy: 0.8822 - val_loss: 0.3595 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 15%|        | 4/26 [03:15<17:12, 46.94s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
            "27025408/27018416 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 10s 120ms/step - loss: 0.3950 - accuracy: 0.8826 - val_loss: 0.3611 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 9s 102ms/step - loss: 0.3724 - accuracy: 0.8837 - val_loss: 0.3598 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 9s 103ms/step - loss: 0.3644 - accuracy: 0.8833 - val_loss: 0.3659 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 19%|        | 5/26 [03:53<15:28, 44.22s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
            "31793152/31790344 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 11s 129ms/step - loss: 0.3703 - accuracy: 0.8830 - val_loss: 0.3596 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 9s 108ms/step - loss: 0.3654 - accuracy: 0.8819 - val_loss: 0.3610 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 9s 108ms/step - loss: 0.3645 - accuracy: 0.8826 - val_loss: 0.3597 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 23%|       | 6/26 [04:33<14:24, 43.22s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "43941888/43941136 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 14s 166ms/step - loss: 0.3697 - accuracy: 0.8757 - val_loss: 0.3688 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 12s 139ms/step - loss: 0.3678 - accuracy: 0.8822 - val_loss: 0.3613 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 12s 139ms/step - loss: 0.3654 - accuracy: 0.8837 - val_loss: 0.3594 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 27%|       | 7/26 [05:23<14:19, 45.26s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
            "71688192/71686520 [==============================] - 1s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 18s 214ms/step - loss: 0.3736 - accuracy: 0.8728 - val_loss: 0.3663 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 16s 183ms/step - loss: 0.3676 - accuracy: 0.8830 - val_loss: 0.3604 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 16s 184ms/step - loss: 0.3644 - accuracy: 0.8834 - val_loss: 0.3674 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 31%|       | 8/26 [06:30<15:29, 51.65s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n",
            "115269632/115263384 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 25s 292ms/step - loss: 0.3735 - accuracy: 0.8735 - val_loss: 0.3607 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 22s 252ms/step - loss: 0.3680 - accuracy: 0.8822 - val_loss: 0.3730 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 22s 253ms/step - loss: 0.3663 - accuracy: 0.8833 - val_loss: 0.3617 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 35%|      | 9/26 [07:57<17:38, 62.27s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n",
            "165240832/165234480 [==============================] - 2s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 32s 373ms/step - loss: 0.3742 - accuracy: 0.8800 - val_loss: 0.3696 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 28s 327ms/step - loss: 0.3649 - accuracy: 0.8830 - val_loss: 0.3630 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 28s 327ms/step - loss: 0.3672 - accuracy: 0.8830 - val_loss: 0.3608 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 38%|      | 10/26 [09:49<20:34, 77.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "258080768/258076736 [==============================] - 2s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 42s 488ms/step - loss: 0.3760 - accuracy: 0.8753 - val_loss: 0.3627 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 38s 441ms/step - loss: 0.3674 - accuracy: 0.8833 - val_loss: 0.3597 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 38s 443ms/step - loss: 0.3710 - accuracy: 0.8822 - val_loss: 0.3594 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 42%|     | 11/26 [12:15<24:26, 97.79s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 2s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 21s 247ms/step - loss: 0.3340 - accuracy: 0.8775 - val_loss: 0.2917 - val_accuracy: 0.8894\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 18s 205ms/step - loss: 0.2656 - accuracy: 0.8949 - val_loss: 0.2672 - val_accuracy: 0.8922\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 18s 207ms/step - loss: 0.2340 - accuracy: 0.9080 - val_loss: 0.2505 - val_accuracy: 0.8908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 46%|     | 12/26 [13:29<21:10, 90.74s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 9s 108ms/step - loss: 0.3215 - accuracy: 0.8811 - val_loss: 0.2727 - val_accuracy: 0.8908\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 8s 88ms/step - loss: 0.2557 - accuracy: 0.8917 - val_loss: 0.2716 - val_accuracy: 0.8908\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 8s 88ms/step - loss: 0.2334 - accuracy: 0.9037 - val_loss: 0.2414 - val_accuracy: 0.8951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|     | 13/26 [14:01<15:48, 72.99s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 5s 55ms/step - loss: 0.2872 - accuracy: 0.8866 - val_loss: 0.2311 - val_accuracy: 0.8994\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 4s 47ms/step - loss: 0.1871 - accuracy: 0.9215 - val_loss: 0.2012 - val_accuracy: 0.9080\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 4s 47ms/step - loss: 0.1598 - accuracy: 0.9331 - val_loss: 0.1820 - val_accuracy: 0.9224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 54%|    | 14/26 [14:16<11:09, 55.78s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 7s 87ms/step - loss: 0.3018 - accuracy: 0.8771 - val_loss: 0.2390 - val_accuracy: 0.9023\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 4s 52ms/step - loss: 0.2046 - accuracy: 0.9095 - val_loss: 0.2019 - val_accuracy: 0.9080\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 4s 51ms/step - loss: 0.1757 - accuracy: 0.9218 - val_loss: 0.1880 - val_accuracy: 0.9181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 58%|    | 15/26 [14:37<08:16, 45.14s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n",
            "19996672/19993432 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 11s 123ms/step - loss: 0.3213 - accuracy: 0.8768 - val_loss: 0.2815 - val_accuracy: 0.8865\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 7s 83ms/step - loss: 0.2573 - accuracy: 0.8920 - val_loss: 0.2466 - val_accuracy: 0.8994\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 7s 82ms/step - loss: 0.2303 - accuracy: 0.9019 - val_loss: 0.2339 - val_accuracy: 0.9023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 65%|   | 17/26 [15:19<05:41, 37.93s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171450368/171446536 [==============================] - 1s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 21s 240ms/step - loss: 0.3820 - accuracy: 0.8451 - val_loss: 0.3242 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 19s 218ms/step - loss: 0.3105 - accuracy: 0.8830 - val_loss: 0.3043 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 19s 219ms/step - loss: 0.2922 - accuracy: 0.8826 - val_loss: 0.2944 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 69%|   | 18/26 [16:27<06:16, 47.01s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171319296/171317808 [==============================] - 2s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 18s 210ms/step - loss: 0.2773 - accuracy: 0.8891 - val_loss: 0.2336 - val_accuracy: 0.9023\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 16s 191ms/step - loss: 0.2033 - accuracy: 0.9160 - val_loss: 0.2098 - val_accuracy: 0.9095\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 17s 192ms/step - loss: 0.1721 - accuracy: 0.9335 - val_loss: 0.1959 - val_accuracy: 0.9296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 73%|  | 19/26 [17:31<06:03, 51.98s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234700800/234698864 [==============================] - 1s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 29s 336ms/step - loss: 0.3720 - accuracy: 0.8666 - val_loss: 0.3425 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 27s 314ms/step - loss: 0.3350 - accuracy: 0.8833 - val_loss: 0.3364 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 27s 315ms/step - loss: 0.3252 - accuracy: 0.8837 - val_loss: 0.3229 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 77%|  | 20/26 [19:08<06:33, 65.51s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234553344/234545216 [==============================] - 3s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 25s 296ms/step - loss: 0.2542 - accuracy: 0.8975 - val_loss: 0.2157 - val_accuracy: 0.8966\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 24s 276ms/step - loss: 0.1778 - accuracy: 0.9273 - val_loss: 0.1823 - val_accuracy: 0.9239\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 24s 277ms/step - loss: 0.1511 - accuracy: 0.9389 - val_loss: 0.1696 - val_accuracy: 0.9239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 81%|  | 21/26 [20:37<06:02, 72.60s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 12s 141ms/step - loss: 0.3621 - accuracy: 0.8731 - val_loss: 0.3528 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 11s 133ms/step - loss: 0.3334 - accuracy: 0.8833 - val_loss: 0.3290 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 11s 132ms/step - loss: 0.3131 - accuracy: 0.8840 - val_loss: 0.3213 - val_accuracy: 0.8836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 85%| | 22/26 [21:18<04:12, 63.12s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 10s 118ms/step - loss: 0.2905 - accuracy: 0.8880 - val_loss: 0.2352 - val_accuracy: 0.8937\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 9s 109ms/step - loss: 0.1956 - accuracy: 0.9229 - val_loss: 0.1903 - val_accuracy: 0.9224\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 10s 111ms/step - loss: 0.1637 - accuracy: 0.9349 - val_loss: 0.1795 - val_accuracy: 0.9224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 88%| | 23/26 [21:55<02:45, 55.18s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 16s 180ms/step - loss: 0.4604 - accuracy: 0.7866 - val_loss: 0.3255 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 13s 151ms/step - loss: 0.3033 - accuracy: 0.8830 - val_loss: 0.2939 - val_accuracy: 0.8836\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 13s 151ms/step - loss: 0.2701 - accuracy: 0.8859 - val_loss: 0.2732 - val_accuracy: 0.8807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 92%|| 24/26 [22:39<01:43, 51.98s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 16s 183ms/step - loss: 0.3348 - accuracy: 0.8830 - val_loss: 0.3105 - val_accuracy: 0.8836\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 16s 181ms/step - loss: 0.2879 - accuracy: 0.8822 - val_loss: 0.2853 - val_accuracy: 0.8851\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 16s 182ms/step - loss: 0.2603 - accuracy: 0.8877 - val_loss: 0.2645 - val_accuracy: 0.8851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 96%|| 25/26 [23:29<00:51, 51.26s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 17s 197ms/step - loss: 0.3087 - accuracy: 0.8844 - val_loss: 0.2817 - val_accuracy: 0.8966\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 15s 179ms/step - loss: 0.2531 - accuracy: 0.8946 - val_loss: 0.2458 - val_accuracy: 0.8937\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 15s 180ms/step - loss: 0.2274 - accuracy: 0.9051 - val_loss: 0.2384 - val_accuracy: 0.8937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|| 26/26 [24:23<00:00, 56.28s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "cSGlHAEc7li6",
        "outputId": "dad18bae-b25a-4bca-d28a-372217f7e6b2"
      },
      "source": [
        "# Convert Results to DataFrame for easy viewing\n",
        "benchmark_df = pd.DataFrame(model_benchmarks)\n",
        "benchmark_df.sort_values('num_model_params', inplace=True) # sort in ascending order of num_model_params column\n",
        "benchmark_df.to_csv('benchmark_df.csv', index=False) # write results to csv file\n",
        "benchmark_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>num_model_params</th>\n",
              "      <th>validation_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>MobileNetV2</td>\n",
              "      <td>2257984</td>\n",
              "      <td>0.918103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>3228864</td>\n",
              "      <td>0.922414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EfficientNetB0</td>\n",
              "      <td>4049571</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NASNetMobile</td>\n",
              "      <td>4269716</td>\n",
              "      <td>0.902299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EfficientNetB1</td>\n",
              "      <td>6575239</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DenseNet121</td>\n",
              "      <td>7037504</td>\n",
              "      <td>0.899425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>EfficientNetB2</td>\n",
              "      <td>7768569</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>EfficientNetB3</td>\n",
              "      <td>10783535</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DenseNet169</td>\n",
              "      <td>12642880</td>\n",
              "      <td>0.932471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>VGG16</td>\n",
              "      <td>14714688</td>\n",
              "      <td>0.880747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>EfficientNetB4</td>\n",
              "      <td>17673823</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DenseNet201</td>\n",
              "      <td>18321984</td>\n",
              "      <td>0.912356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>VGG19</td>\n",
              "      <td>20024384</td>\n",
              "      <td>0.885057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Xception</td>\n",
              "      <td>20861480</td>\n",
              "      <td>0.893678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>InceptionV3</td>\n",
              "      <td>21802784</td>\n",
              "      <td>0.895115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>ResNet50V2</td>\n",
              "      <td>23564800</td>\n",
              "      <td>0.922414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ResNet50</td>\n",
              "      <td>23587712</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>EfficientNetB5</td>\n",
              "      <td>28513527</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>EfficientNetB6</td>\n",
              "      <td>40960143</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ResNet101V2</td>\n",
              "      <td>42626560</td>\n",
              "      <td>0.929598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ResNet101</td>\n",
              "      <td>42658176</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>InceptionResNetV2</td>\n",
              "      <td>54336736</td>\n",
              "      <td>0.890805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ResNet152V2</td>\n",
              "      <td>58331648</td>\n",
              "      <td>0.923851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ResNet152</td>\n",
              "      <td>58370944</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>EfficientNetB7</td>\n",
              "      <td>64097687</td>\n",
              "      <td>0.883621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           model_name  num_model_params  validation_accuracy\n",
              "14        MobileNetV2           2257984             0.918103\n",
              "13          MobileNet           3228864             0.922414\n",
              "3      EfficientNetB0           4049571             0.883621\n",
              "15       NASNetMobile           4269716             0.902299\n",
              "4      EfficientNetB1           6575239             0.883621\n",
              "0         DenseNet121           7037504             0.899425\n",
              "5      EfficientNetB2           7768569             0.883621\n",
              "6      EfficientNetB3          10783535             0.883621\n",
              "1         DenseNet169          12642880             0.932471\n",
              "22              VGG16          14714688             0.880747\n",
              "7      EfficientNetB4          17673823             0.883621\n",
              "2         DenseNet201          18321984             0.912356\n",
              "23              VGG19          20024384             0.885057\n",
              "24           Xception          20861480             0.893678\n",
              "12        InceptionV3          21802784             0.895115\n",
              "21         ResNet50V2          23564800             0.922414\n",
              "20           ResNet50          23587712             0.883621\n",
              "8      EfficientNetB5          28513527             0.883621\n",
              "9      EfficientNetB6          40960143             0.883621\n",
              "17        ResNet101V2          42626560             0.929598\n",
              "16          ResNet101          42658176             0.883621\n",
              "11  InceptionResNetV2          54336736             0.890805\n",
              "19        ResNet152V2          58331648             0.923851\n",
              "18          ResNet152          58370944             0.883621\n",
              "10     EfficientNetB7          64097687             0.883621"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhDZiwkkFK06"
      },
      "source": [
        "benchmark_df = benchmark_df.sort_values(by='validation_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usY4JmWTFoNO"
      },
      "source": [
        "benchmark_df.to_csv(\"Keras_pretrained_model_val_accuracy.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}